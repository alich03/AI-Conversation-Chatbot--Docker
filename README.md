Hereâ€™s a **README.md** file with clear instructions on how to set up and run your **Docker Compose** environment. ğŸš€  

---

### **ğŸ“˜ README.md**

```md
# ğŸ› ï¸ RAG-Based Chatbot with Streamlit Frontend & FastAPI Backend

This project consists of a **Retrieval-Augmented Generation (RAG) API** powered by **FastAPI** and a **Streamlit-based frontend** for user interaction. The system enables PDF uploads, document processing, and conversational AI responses.

---

## ğŸš€ **Getting Started**

### **1ï¸âƒ£ Prerequisites**
Ensure you have the following installed on your machine:
- **Docker**: [Download & Install](https://www.docker.com/get-started)
- **Docker Compose**: (Comes with Docker Desktop)
  
---

## ğŸ”§ **Installation & Setup**

### **2ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/alich03/AI-Conversation-Chatbot--Docker.git
cd rag-chatbot
```

---

### **3ï¸âƒ£ Create a `.env` File**
Before running the application, create a `.env` file in the **RAG_API** directory and add your OpenAI API key:

```bash
cd RAG_API
touch .env
```

Inside the `.env` file, add:
```
OPENAI_API_KEY=your_openai_api_key_here
```
> Replace `your_openai_api_key_here` with your actual OpenAI API key.

---


### **3ï¸âƒ£ Build & Run Containers**
Use Docker Compose to build and start both services (**FastAPI Backend** & **Streamlit Frontend**).
```bash
docker-compose up --build
```
> This will:
> - Build & start the **RAG API** (`rag-api`)
> - Build & start the **Streamlit Frontend** (`rag-frontend`)

---

## ğŸ¯ **Accessing the Application**
Once the services are up, you can access them at:
- **Frontend (Chat Interface)**: [http://localhost:8501](http://localhost:8501)
- **Backend (FastAPI Docs)**: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ› ï¸ **Project Structure**
```
/rag-chatbot
â”‚â”€â”€ RAG_API/           # FastAPI Backend
â”‚   â”œâ”€â”€ main.py        # Main API logic
â”‚   â”œâ”€â”€ requirements.txt  # Dependencies
â”‚   â”œâ”€â”€ Dockerfile     # Docker setup for API
â”‚â”€â”€ RAG_Frontend/      # Streamlit Frontend
â”‚   â”œâ”€â”€ app.py         # Main frontend logic
â”‚   â”œâ”€â”€ Dockerfile     # Docker setup for frontend
â”‚â”€â”€ docker-compose.yml # Docker Compose configuration
â”‚â”€â”€ README.md          # Documentation
```

---

## ğŸ³ **Stopping the Containers**
To stop the running containers, use:
```bash
docker-compose down
```
> This will shut down all running services.

---

## âš™ï¸ **Common Issues & Fixes**
### **1. API Not Accessible?**
- Ensure the backend runs on port `8000`. If the issue persists, modify the `uvicorn` command in the **FastAPI Dockerfile**:
    ```dockerfile
    CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    ```
- Rebuild the container:
    ```bash
    docker-compose up --build
    ```

### **2. Docker Compose Fails to Start?**
Try:
```bash
docker-compose down --remove-orphans
docker-compose up --build
```

---

## ğŸ“œ **License**
This project is open-source and available under the [MIT License](LICENSE).

---

## ğŸ‘¨â€ğŸ’» **Author**
Developed by **Ali Hasnain** ğŸš€  
For any issues or feature requests, please [open an issue](https://github.com/alich03/AI-Conversation-Chatbot--Docker.git/issues).

---

Happy Coding! ğŸ‰
```

---

### **ğŸ“Œ Key Highlights of the README**
âœ… **Clear setup instructions** for cloning, building, and running  
âœ… **Access URLs** for frontend and backend  
âœ… **Troubleshooting section** for common Docker issues  
âœ… **Proper project structure breakdown**  

This README ensures **anyone** can set up and run your project **easily!** ğŸš€